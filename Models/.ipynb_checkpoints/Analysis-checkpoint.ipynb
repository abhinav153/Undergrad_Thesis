{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29025c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Desktop\\Undergrad_Thesis\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b67474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from model import ANN\n",
    "from torch import nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,classification_report\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0e102e",
   "metadata": {},
   "source": [
    "## Load all data files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5222ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'Models/post_processed/'\n",
    "X_raw_50 = np.load(file=directory+'50/X_raw.npy')\n",
    "y_raw_50 = np.load(file=directory+'50/Y_raw.npy')\n",
    "X_filtered_50 = np.load(file=directory+'50/X_filtered.npy')\n",
    "y_filtered_50 = np.load(file=directory+'50/Y_filtered.npy')\n",
    "with open(directory+'50/labels','rb') as fp:\n",
    "    columns_50 = pickle.load(fp)\n",
    "    \n",
    "\n",
    "X_raw_100 = np.load(file=directory+'100/X_raw.npy')\n",
    "y_raw_100 = np.load(file=directory+'100/Y_raw.npy')\n",
    "X_filtered_100 = np.load(file=directory+'100/X_filtered.npy')\n",
    "y_filtered_100 = np.load(file=directory+'100/Y_filtered.npy')\n",
    "with open(directory+'100/labels','rb') as fp:\n",
    "    columns_100 = pickle.load(fp)\n",
    "   \n",
    "\n",
    "X_raw_150 = np.load(file=directory+'150/X_raw.npy')\n",
    "y_raw_150 = np.load(file=directory+'150/Y_raw.npy')\n",
    "X_filtered_150 = np.load(file=directory+'150/X_filtered.npy')\n",
    "y_filtered_150 = np.load(file=directory+'150/Y_filtered.npy')\n",
    "with open(directory+'150/labels','rb') as fp:\n",
    "    columns_150 = pickle.load(fp)\n",
    "    \n",
    "\n",
    "X_raw_200 = np.load(file=directory+'200/X_raw.npy')\n",
    "y_raw_200 = np.load(file=directory+'200/Y_raw.npy')\n",
    "X_filtered_200 = np.load(file=directory+'200/X_filtered.npy')\n",
    "y_filtered_200 = np.load(file=directory+'200/Y_filtered.npy')\n",
    "with open(directory+'200/labels','rb') as fp:\n",
    "    columns_200 = pickle.load(fp)\n",
    "    \n",
    "X_raw_250 = np.load(file=directory+'250/X_raw.npy')\n",
    "y_raw_250 = np.load(file=directory+'250/Y_raw.npy')\n",
    "X_filtered_250 = np.load(file=directory+'250/X_filtered.npy')\n",
    "y_filtered_250 = np.load(file=directory+'250/Y_filtered.npy')\n",
    "with open(directory+'250/labels','rb') as fp:\n",
    "    columns_250 = pickle.load(fp)\n",
    "    \n",
    "X_raw_300 = np.load(file=directory+'300/X_raw.npy')\n",
    "y_raw_300 = np.load(file=directory+'300/Y_raw.npy')\n",
    "X_filtered_300 = np.load(file=directory+'300/X_filtered.npy')\n",
    "y_filtered_300 = np.load(file=directory+'300/Y_filtered.npy')\n",
    "with open(directory+'200/labels','rb') as fp:\n",
    "    columns_300 = pickle.load(fp)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc8b218",
   "metadata": {},
   "source": [
    "## Analysis 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0275ae0",
   "metadata": {},
   "source": [
    "###  Visualize mutual information scores for each segment length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b4707fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7816\\3201063728.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmi_scores_raw_50\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmutual_info_classif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_raw_50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_raw_50\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmi_scores_raw_50\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmi_scores_raw_50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Raw 50\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns_50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmi_scores_filtered_50\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmutual_info_classif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_filtered_50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_filtered_50\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmi_scores_filtered_50\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmi_scores_filtered_50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Filtered 50\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns_50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Thesis\\lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py\u001b[0m in \u001b[0;36mmutual_info_classif\u001b[1;34m(X, y, discrete_features, n_neighbors, copy, random_state)\u001b[0m\n\u001b[0;32m    462\u001b[0m     \"\"\"\n\u001b[0;32m    463\u001b[0m     \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_estimate_mi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscrete_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\Thesis\\lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py\u001b[0m in \u001b[0;36m_estimate_mi\u001b[1;34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state)\u001b[0m\n\u001b[0;32m    254\u001b[0m            \u001b[0mData\u001b[0m \u001b[0mSets\u001b[0m\u001b[0;31m\"\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mPLoS\u001b[0m \u001b[0mONE\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2014.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \"\"\"\n\u001b[1;32m--> 256\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mdiscrete_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m     \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Thesis\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    974\u001b[0m         \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m         \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    977\u001b[0m     )\n\u001b[0;32m    978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Thesis\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"allow-nan\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    801\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Thesis\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    114\u001b[0m             raise ValueError(\n\u001b[0;32m    115\u001b[0m                 msg_err.format(\n\u001b[1;32m--> 116\u001b[1;33m                     \u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m                 )\n\u001b[0;32m    118\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "mi_scores_raw_50 = mutual_info_classif(X_raw_50,y_raw_50.ravel())\n",
    "mi_scores_raw_50 = pd.Series(mi_scores_raw_50, name=\"Raw 50\", index=columns_50)\n",
    "mi_scores_filtered_50 = mutual_info_classif(X_filtered_50,y_filtered_50.ravel())\n",
    "mi_scores_filtered_50 = pd.Series(mi_scores_filtered_50,name=\"Filtered 50\",index=columns_50)\n",
    "\n",
    "mi_scores_raw_100 = mutual_info_classif(X_raw_100,y_raw_100.ravel())\n",
    "mi_scores_raw_100 = pd.Series(mi_scores_raw_100, name=\"Raw 100\", index=columns_100)\n",
    "mi_scores_filtered_100 = mutual_info_classif(X_filtered_100,y_filtered_100.ravel())\n",
    "mi_scores_filtered_100 = pd.Series(mi_scores_filtered_100,name=\"Filtered 100\",index=columns_100)\n",
    "\n",
    "mi_scores_raw_150 = mutual_info_classif(X_raw_150,y_raw_150.ravel())\n",
    "mi_scores_raw_150 = pd.Series(mi_scores_raw_150, name=\"Raw 150\", index=columns_150)\n",
    "mi_scores_filtered_150 = mutual_info_classif(X_filtered_150,y_filtered_150.ravel())\n",
    "mi_scores_filtered_150 = pd.Series(mi_scores_filtered_150,name=\"Filtered 150\",index=columns_150)\n",
    "\n",
    "mi_scores_raw_200 = mutual_info_classif(X_raw_200,y_raw_200.ravel())\n",
    "mi_scores_raw_200 = pd.Series(mi_scores_raw_200, name=\"Raw 200\", index=columns_200)\n",
    "mi_scores_filtered_200 = mutual_info_classif(X_filtered_200,y_filtered_200.ravel())\n",
    "mi_scores_filtered_200 = pd.Series(mi_scores_filtered_200,name=\"Filtered 200\",index=columns_200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75c6edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mi_scores = pd.concat([mi_scores_raw_50,\n",
    "                          mi_scores_filtered_50,\n",
    "                          mi_scores_raw_100,\n",
    "                          mi_scores_filtered_100,\n",
    "                          mi_scores_raw_150,\n",
    "                          mi_scores_filtered_150,\n",
    "                          mi_scores_raw_200,\n",
    "                          mi_scores_filtered_200],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b6a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_mi_scores,vmin=0,vmax=1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f74f3a",
   "metadata": {},
   "source": [
    "### Choose best 5 features by analysing heat map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cd24d6",
   "metadata": {},
   "source": [
    "## Analysis 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649a6fe2",
   "metadata": {},
   "source": [
    "### Visualize Model Performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab72350b",
   "metadata": {},
   "source": [
    "#### Training Artificial Neural Net (With All Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9397d750",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing models\n",
    "ann_50_raw = ANN(X_raw_50,y_raw_50,'ANN 50 Raw')\n",
    "ann_50_filtered = ANN(X_filtered_50,y_filtered_50,'ANN 50 Filtered')\n",
    "ann_100_raw = ANN(X_raw_100,y_filtered_100,'ANN 100 Raw')\n",
    "ann_100_filtered = ANN(X_filtered_100,y_raw_100,'ANN 100 Filtered')\n",
    "ann_150_raw = ANN(X_raw_150,y_raw_150,'ANN 150 Raw')\n",
    "ann_150_filtered = ANN(X_filtered_150,y_filtered_150,'ANN 150 Filtered')\n",
    "ann_200_raw = ANN(X_raw_200,y_raw_200,'ANN 200 Raw')\n",
    "ann_200_filtered = ANN(X_filtered_200,y_filtered_200,'ANN 200 FIltered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de6138a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Now Training for window length:50 Raw & Filtered\")\n",
    "print('Training Raw')\n",
    "val_50_raw_losses = ann_50_raw.train()\n",
    "print('Training Filtered')\n",
    "val_50_filtered_losses = ann_50_filtered.train()\n",
    "test_accuracy_50_raw = ann_50_raw.test()\n",
    "test_accuracy_50_filtered = ann_50_filtered.test()\n",
    "\n",
    "print(f\"Now Training for window length:100 Raw & Filtered\")\n",
    "print('Training Raw')\n",
    "val_100_raw_losses = ann_100_raw.train()\n",
    "print('Training Filtered')\n",
    "val_100_filtered_losses = ann_100_filtered.train()\n",
    "test_accuracy_100_raw = ann_100_raw.test()\n",
    "test_accuracy_100_filtered = ann_100_filtered.test()\n",
    "\n",
    "print(f\"Now Training for window length:150 Raw & Filtered\")\n",
    "print('Training Raw')\n",
    "val_150_raw_losses = ann_150_raw.train()\n",
    "print('Training Filtered')\n",
    "val_150_filtered_losses = ann_150_filtered.train()\n",
    "test_accuracy_150_raw = ann_150_raw.test()\n",
    "test_accuracy_150_filtered = ann_150_filtered.test()\n",
    "\n",
    "print(f\"Now Training for window length:200 Raw & Filtered\")\n",
    "print('Training Raw')\n",
    "val_200_raw_losses = ann_200_raw.train()\n",
    "print('Training Filtered')\n",
    "val_200_filtered_losses = ann_200_filtered.train()\n",
    "test_accuracy_200_raw = ann_200_raw.test()\n",
    "test_accuracy_200_filtered = ann_200_filtered.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b797b8c",
   "metadata": {},
   "source": [
    "#### Ploting losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193d1374",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting validation losses during the training phase\n",
    "labels = list(val_50_raw_losses.keys())\n",
    "plt.xticks(rotation=90)\n",
    "plt.plot(labels,list(val_50_raw_losses.values()),label = '50_raw')\n",
    "plt.plot(labels,list(val_50_filtered_losses.values()),label = '50 filtered')\n",
    "\n",
    "plt.plot(labels,list(val_100_raw_losses.values()),label = '100_raw')\n",
    "plt.plot(labels,list(val_100_filtered_losses.values()),label = '100 filtered')\n",
    "\n",
    "plt.plot(labels,list(val_150_raw_losses.values()),label = '150_raw')\n",
    "plt.plot(labels,list(val_150_filtered_losses.values()),label = '150 filtered')\n",
    "\n",
    "plt.plot(labels,list(val_200_raw_losses.values()),label = '200_raw')\n",
    "plt.plot(labels,list(val_200_filtered_losses.values()),label = '200 filtered')\n",
    "plt.legend(bbox_to_anchor=(1.02, 0.1), loc='upper left', borderaxespad=0)\n",
    "plt.title('Validation Loss during Training')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98885865",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting training accuracy\n",
    "labels = ['50_raw','50_filtered','100_raw','100_filtered','150_raw','150_filtered','200_raw','200_filtered',]\n",
    "plt.xticks(rotation=90)\n",
    "y = [test_accuracy_50_raw,\n",
    "     test_accuracy_50_filtered,\n",
    "     test_accuracy_100_raw,\n",
    "     test_accuracy_100_filtered,\n",
    "     test_accuracy_150_raw,\n",
    "     test_accuracy_150_filtered,\n",
    "     test_accuracy_200_raw,\n",
    "     test_accuracy_200_filtered]\n",
    "plt.barh(labels,y)\n",
    "plt.title('Test Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da52e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot confusion matrix\n",
    "def get_confusion_matrix(X,y_true,model):\n",
    "    X = torch.from_numpy(X).float()\n",
    "    output = model.model(X)\n",
    "    argmax = torch.argmax(output,dim=1)\n",
    "    predictions = deepcopy(argmax)\n",
    "    print(model.categories)\n",
    "    for i in range(len(argmax)):\n",
    "        index = argmax[i]\n",
    "        predictions[i] = model.categories[index]\n",
    "    cm = confusion_matrix(y_true,predictions,labels=model.categories)\n",
    "    display = ConfusionMatrixDisplay(cm,display_labels=[int(i) for i in model.categories])\n",
    "    print('Confusion Matrix for ',model.name)\n",
    "    display.plot()\n",
    "\n",
    "get_confusion_matrix(X_raw_50,y_raw_50,ann_50_raw)\n",
    "get_confusion_matrix(X_filtered_100,y_raw_100,ann_100_filtered)\n",
    "get_confusion_matrix(X_filtered_150,y_raw_150,ann_150_filtered)\n",
    "get_confusion_matrix(X_filtered_200,y_raw_200,ann_200_filtered)\n",
    "plt.xticks(rotation=90) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70fdd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot classification report\n",
    "def get_classification_report(X,y_true,model,):\n",
    "    X = torch.from_numpy(X).float()\n",
    "    output = model.model(X)\n",
    "    argmax = torch.argmax(output,dim=1)\n",
    "    predictions = deepcopy(argmax)\n",
    "    print(model.categories)\n",
    "    for i in range(len(argmax)):\n",
    "        index = argmax[i]\n",
    "        predictions[i] = model.categories[index]\n",
    "    cr = classification_report(y_true,predictions,target_names=[str(int(i)) for i in model.categories])\n",
    "    print('Classification Report for ',model.name)\n",
    "    print(cr)\n",
    "get_classification_report(X_raw_50,y_raw_50,ann_50_raw)\n",
    "get_classification_report(X_filtered_50,y_filtered_50,ann_50_filtered)\n",
    "get_classification_report(X_raw_100,y_raw_100,ann_100_raw)\n",
    "get_classification_report(X_filtered_100,y_filtered_100,ann_100_filtered)\n",
    "get_classification_report(X_raw_150,y_raw_150,ann_150_raw)\n",
    "get_classification_report(X_filtered_150,y_filtered_150,ann_150_filtered)\n",
    "get_classification_report(X_raw_200,y_raw_200,ann_200_raw)\n",
    "get_classification_report(X_filtered_50,y_filtered_50,ann_50_filtered)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc851fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
