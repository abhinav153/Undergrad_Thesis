{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29025c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Desktop\\Undergrad_Thesis\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b67474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from model import ANN\n",
    "from torch import nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,classification_report\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0e102e",
   "metadata": {},
   "source": [
    "## Load all data files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5222ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'Models/post_processed/'\n",
    "X_raw_50 = np.load(file=directory+'50/X_raw.npy')\n",
    "y_raw_50 = np.load(file=directory+'50/Y_raw.npy')\n",
    "X_filtered_50 = np.load(file=directory+'50/X_filtered.npy')\n",
    "y_filtered_50 = np.load(file=directory+'50/Y_filtered.npy')\n",
    "with open(directory+'50/labels','rb') as fp:\n",
    "    columns_50 = pickle.load(fp)\n",
    "    \n",
    "\n",
    "X_raw_100 = np.load(file=directory+'100/X_raw.npy')\n",
    "y_raw_100 = np.load(file=directory+'100/Y_raw.npy')\n",
    "X_filtered_100 = np.load(file=directory+'100/X_filtered.npy')\n",
    "y_filtered_100 = np.load(file=directory+'100/Y_filtered.npy')\n",
    "with open(directory+'100/labels','rb') as fp:\n",
    "    columns_100 = pickle.load(fp)\n",
    "   \n",
    "\n",
    "X_raw_150 = np.load(file=directory+'150/X_raw.npy')\n",
    "y_raw_150 = np.load(file=directory+'150/Y_raw.npy')\n",
    "X_filtered_150 = np.load(file=directory+'150/X_filtered.npy')\n",
    "y_filtered_150 = np.load(file=directory+'150/Y_filtered.npy')\n",
    "with open(directory+'150/labels','rb') as fp:\n",
    "    columns_150 = pickle.load(fp)\n",
    "    \n",
    "\n",
    "X_raw_200 = np.load(file=directory+'200/X_raw.npy')\n",
    "y_raw_200 = np.load(file=directory+'200/Y_raw.npy')\n",
    "X_filtered_200 = np.load(file=directory+'200/X_filtered.npy')\n",
    "y_filtered_200 = np.load(file=directory+'200/Y_filtered.npy')\n",
    "with open(directory+'200/labels','rb') as fp:\n",
    "    columns_200 = pickle.load(fp)\n",
    "    \n",
    "X_raw_250 = np.load(file=directory+'250/X_raw.npy')\n",
    "y_raw_250 = np.load(file=directory+'250/Y_raw.npy')\n",
    "X_filtered_250 = np.load(file=directory+'250/X_filtered.npy')\n",
    "y_filtered_250 = np.load(file=directory+'250/Y_filtered.npy')\n",
    "with open(directory+'250/labels','rb') as fp:\n",
    "    columns_250 = pickle.load(fp)\n",
    "    \n",
    "X_raw_300 = np.load(file=directory+'300/X_raw.npy')\n",
    "y_raw_300 = np.load(file=directory+'300/Y_raw.npy')\n",
    "X_filtered_300 = np.load(file=directory+'300/X_filtered.npy')\n",
    "y_filtered_300 = np.load(file=directory+'300/Y_filtered.npy')\n",
    "with open(directory+'200/labels','rb') as fp:\n",
    "    columns_300 = pickle.load(fp)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc8b218",
   "metadata": {},
   "source": [
    "## Analysis 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0275ae0",
   "metadata": {},
   "source": [
    "###  Visualize mutual information scores for each segment length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4707fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_scores_raw_50 = mutual_info_classif(X_raw_50,y_raw_50.ravel())\n",
    "mi_scores_raw_50 = pd.Series(mi_scores_raw_50, name=\"Raw 50\", index=columns_50)\n",
    "mi_scores_filtered_50 = mutual_info_classif(X_filtered_50,y_filtered_50.ravel())\n",
    "mi_scores_filtered_50 = pd.Series(mi_scores_filtered_50,name=\"Filtered 50\",index=columns_50)\n",
    "\n",
    "mi_scores_raw_100 = mutual_info_classif(X_raw_100,y_raw_100.ravel())\n",
    "mi_scores_raw_100 = pd.Series(mi_scores_raw_100, name=\"Raw 100\", index=columns_100)\n",
    "mi_scores_filtered_100 = mutual_info_classif(X_filtered_100,y_filtered_100.ravel())\n",
    "mi_scores_filtered_100 = pd.Series(mi_scores_filtered_100,name=\"Filtered 100\",index=columns_100)\n",
    "\n",
    "mi_scores_raw_150 = mutual_info_classif(X_raw_150,y_raw_150.ravel())\n",
    "mi_scores_raw_150 = pd.Series(mi_scores_raw_150, name=\"Raw 150\", index=columns_150)\n",
    "mi_scores_filtered_150 = mutual_info_classif(X_filtered_150,y_filtered_150.ravel())\n",
    "mi_scores_filtered_150 = pd.Series(mi_scores_filtered_150,name=\"Filtered 150\",index=columns_150)\n",
    "\n",
    "mi_scores_raw_200 = mutual_info_classif(X_raw_200,y_raw_200.ravel())\n",
    "mi_scores_raw_200 = pd.Series(mi_scores_raw_200, name=\"Raw 200\", index=columns_200)\n",
    "mi_scores_filtered_200 = mutual_info_classif(X_filtered_200,y_filtered_200.ravel())\n",
    "mi_scores_filtered_200 = pd.Series(mi_scores_filtered_200,name=\"Filtered 200\",index=columns_200)\n",
    "\n",
    "mi_scores_raw_250 = mutual_info_classif(X_raw_250,y_raw_250.ravel())\n",
    "mi_scores_raw_250 = pd.Series(mi_scores_raw_250, name=\"Raw 250\", index=columns_250)\n",
    "mi_scores_filtered_250 = mutual_info_classif(X_filtered_250,y_filtered_250.ravel())\n",
    "mi_scores_filtered_250 = pd.Series(mi_scores_filtered_250,name=\"Filtered 200\",index=columns_250)\n",
    "\n",
    "mi_scores_raw_300 = mutual_info_classif(X_raw_300,y_raw_300.ravel())\n",
    "mi_scores_raw_300 = pd.Series(mi_scores_raw_300, name=\"Raw 300\", index=columns_300)\n",
    "mi_scores_filtered_300 = mutual_info_classif(X_filtered_300,y_filtered_300.ravel())\n",
    "mi_scores_filtered_300 = pd.Series(mi_scores_filtered_300,name=\"Filtered 300\",index=columns_300)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75c6edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mi_scores = pd.concat([mi_scores_raw_50,\n",
    "                          mi_scores_filtered_50,\n",
    "                          mi_scores_raw_100,\n",
    "                          mi_scores_filtered_100,\n",
    "                          mi_scores_raw_150,\n",
    "                          mi_scores_filtered_150,\n",
    "                          mi_scores_raw_200,\n",
    "                          mi_scores_filtered_200,\n",
    "                          mi_scores_raw_250,\n",
    "                          mi_scores_filtered_250,\n",
    "                          mi_scores_raw_300,\n",
    "                          mi_scores_filtered_300,],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b6a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_mi_scores,vmin=0,vmax=1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f74f3a",
   "metadata": {},
   "source": [
    "### Choose best 5 features by analysing heat map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cd24d6",
   "metadata": {},
   "source": [
    "## Analysis 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649a6fe2",
   "metadata": {},
   "source": [
    "### Visualize Model Performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab72350b",
   "metadata": {},
   "source": [
    "#### Training Artificial Neural Net (With All Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9397d750",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing models\n",
    "ann_50_raw = ANN(X_raw_50,y_raw_50,'ANN 50 Raw')\n",
    "ann_50_filtered = ANN(X_filtered_50,y_filtered_50,'ANN 50 Filtered')\n",
    "ann_100_raw = ANN(X_raw_100,y_filtered_100,'ANN 100 Raw')\n",
    "ann_100_filtered = ANN(X_filtered_100,y_raw_100,'ANN 100 Filtered')\n",
    "ann_150_raw = ANN(X_raw_150,y_raw_150,'ANN 150 Raw')\n",
    "ann_150_filtered = ANN(X_filtered_150,y_filtered_150,'ANN 150 Filtered')\n",
    "ann_200_raw = ANN(X_raw_200,y_raw_200,'ANN 200 Raw')\n",
    "ann_200_filtered = ANN(X_filtered_200,y_filtered_200,'ANN 200 FIltered')\n",
    "ann_250_raw = ANN(X_raw_250,y_raw_250,'ANN 250 Raw')\n",
    "ann_250_filtered = ANN(X_filtered_250,y_filtered_250,'ANN 250 FIltered')\n",
    "ann_300_raw = ANN(X_raw_300,y_raw_300,'ANN 300 Raw')\n",
    "ann_300_filtered = ANN(X_filtered_300,y_filtered_300,'ANN 300 FIltered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de6138a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Now Training for window length:50 Raw & Filtered\")\n",
    "print('Training Raw')\n",
    "val_50_raw_losses = ann_50_raw.train()\n",
    "print('Training Filtered')\n",
    "val_50_filtered_losses = ann_50_filtered.train()\n",
    "test_accuracy_50_raw = ann_50_raw.test()\n",
    "test_accuracy_50_filtered = ann_50_filtered.test()\n",
    "\n",
    "print(f\"Now Training for window length:100 Raw & Filtered\")\n",
    "print('Training Raw')\n",
    "val_100_raw_losses = ann_100_raw.train()\n",
    "print('Training Filtered')\n",
    "val_100_filtered_losses = ann_100_filtered.train()\n",
    "test_accuracy_100_raw = ann_100_raw.test()\n",
    "test_accuracy_100_filtered = ann_100_filtered.test()\n",
    "\n",
    "print(f\"Now Training for window length:150 Raw & Filtered\")\n",
    "print('Training Raw')\n",
    "val_150_raw_losses = ann_150_raw.train()\n",
    "print('Training Filtered')\n",
    "val_150_filtered_losses = ann_150_filtered.train()\n",
    "test_accuracy_150_raw = ann_150_raw.test()\n",
    "test_accuracy_150_filtered = ann_150_filtered.test()\n",
    "\n",
    "print(f\"Now Training for window length:200 Raw & Filtered\")\n",
    "print('Training Raw')\n",
    "val_200_raw_losses = ann_200_raw.train()\n",
    "print('Training Filtered')\n",
    "val_200_filtered_losses = ann_200_filtered.train()\n",
    "test_accuracy_200_raw = ann_200_raw.test()\n",
    "test_accuracy_200_filtered = ann_200_filtered.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b797b8c",
   "metadata": {},
   "source": [
    "#### Ploting losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193d1374",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting validation losses during the training phase\n",
    "labels = list(val_50_raw_losses.keys())\n",
    "plt.xticks(rotation=90)\n",
    "plt.plot(labels,list(val_50_raw_losses.values()),label = '50_raw')\n",
    "plt.plot(labels,list(val_50_filtered_losses.values()),label = '50 filtered')\n",
    "\n",
    "plt.plot(labels,list(val_100_raw_losses.values()),label = '100_raw')\n",
    "plt.plot(labels,list(val_100_filtered_losses.values()),label = '100 filtered')\n",
    "\n",
    "plt.plot(labels,list(val_150_raw_losses.values()),label = '150_raw')\n",
    "plt.plot(labels,list(val_150_filtered_losses.values()),label = '150 filtered')\n",
    "\n",
    "plt.plot(labels,list(val_200_raw_losses.values()),label = '200_raw')\n",
    "plt.plot(labels,list(val_200_filtered_losses.values()),label = '200 filtered')\n",
    "plt.legend(bbox_to_anchor=(1.02, 0.1), loc='upper left', borderaxespad=0)\n",
    "plt.title('Validation Loss during Training')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98885865",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting training accuracy\n",
    "labels = ['50_raw','50_filtered','100_raw','100_filtered','150_raw','150_filtered','200_raw','200_filtered',]\n",
    "plt.xticks(rotation=90)\n",
    "y = [test_accuracy_50_raw,\n",
    "     test_accuracy_50_filtered,\n",
    "     test_accuracy_100_raw,\n",
    "     test_accuracy_100_filtered,\n",
    "     test_accuracy_150_raw,\n",
    "     test_accuracy_150_filtered,\n",
    "     test_accuracy_200_raw,\n",
    "     test_accuracy_200_filtered]\n",
    "plt.barh(labels,y)\n",
    "plt.title('Test Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da52e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot confusion matrix\n",
    "def get_confusion_matrix(X,y_true,model):\n",
    "    X = torch.from_numpy(X).float()\n",
    "    output = model.model(X)\n",
    "    argmax = torch.argmax(output,dim=1)\n",
    "    predictions = deepcopy(argmax)\n",
    "    print(model.categories)\n",
    "    for i in range(len(argmax)):\n",
    "        index = argmax[i]\n",
    "        predictions[i] = model.categories[index]\n",
    "    cm = confusion_matrix(y_true,predictions,labels=model.categories)\n",
    "    display = ConfusionMatrixDisplay(cm,display_labels=[int(i) for i in model.categories])\n",
    "    print('Confusion Matrix for ',model.name)\n",
    "    display.plot()\n",
    "\n",
    "get_confusion_matrix(X_raw_50,y_raw_50,ann_50_raw)\n",
    "get_confusion_matrix(X_filtered_100,y_raw_100,ann_100_filtered)\n",
    "get_confusion_matrix(X_filtered_150,y_raw_150,ann_150_filtered)\n",
    "get_confusion_matrix(X_filtered_200,y_raw_200,ann_200_filtered)\n",
    "plt.xticks(rotation=90) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70fdd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot classification report\n",
    "def get_classification_report(X,y_true,model,):\n",
    "    X = torch.from_numpy(X).float()\n",
    "    output = model.model(X)\n",
    "    argmax = torch.argmax(output,dim=1)\n",
    "    predictions = deepcopy(argmax)\n",
    "    print(model.categories)\n",
    "    for i in range(len(argmax)):\n",
    "        index = argmax[i]\n",
    "        predictions[i] = model.categories[index]\n",
    "    cr = classification_report(y_true,predictions,target_names=[str(int(i)) for i in model.categories])\n",
    "    print('Classification Report for ',model.name)\n",
    "    print(cr)\n",
    "get_classification_report(X_raw_50,y_raw_50,ann_50_raw)\n",
    "get_classification_report(X_filtered_50,y_filtered_50,ann_50_filtered)\n",
    "get_classification_report(X_raw_100,y_raw_100,ann_100_raw)\n",
    "get_classification_report(X_filtered_100,y_filtered_100,ann_100_filtered)\n",
    "get_classification_report(X_raw_150,y_raw_150,ann_150_raw)\n",
    "get_classification_report(X_filtered_150,y_filtered_150,ann_150_filtered)\n",
    "get_classification_report(X_raw_200,y_raw_200,ann_200_raw)\n",
    "get_classification_report(X_filtered_50,y_filtered_50,ann_50_filtered)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc851fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
