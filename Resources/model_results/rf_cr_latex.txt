\begin{tabular}{lrrrr}
\toprule
{} &  precision &    recall &  f1-score &     support \\
\midrule
1            &   0.847222 &  0.762500 &  0.802632 &   160.00000 \\
2            &   0.826347 &  0.826347 &  0.826347 &   167.00000 \\
4            &   0.805714 &  0.844311 &  0.824561 &   167.00000 \\
5            &   0.808383 &  0.859873 &  0.833333 &   157.00000 \\
6            &   0.907285 &  0.825301 &  0.864353 &   166.00000 \\
7            &   0.778409 &  0.850932 &  0.813056 &   161.00000 \\
9            &   0.826923 &  0.796296 &  0.811321 &   162.00000 \\
10           &   0.821656 &  0.791411 &  0.806250 &   163.00000 \\
12           &   0.763158 &  0.873494 &  0.814607 &   166.00000 \\
14           &   0.753247 &  0.738854 &  0.745981 &   157.00000 \\
15           &   0.738636 &  0.792683 &  0.764706 &   164.00000 \\
17           &   0.843931 &  0.863905 &  0.853801 &   169.00000 \\
18           &   0.780000 &  0.754839 &  0.767213 &   155.00000 \\
20           &   0.871951 &  0.851190 &  0.861446 &   168.00000 \\
23           &   0.735632 &  0.766467 &  0.750733 &   167.00000 \\
24           &   0.844595 &  0.739645 &  0.788644 &   169.00000 \\
25           &   0.714286 &  0.762712 &  0.737705 &   177.00000 \\
26           &   0.721854 &  0.608939 &  0.660606 &   179.00000 \\
43           &   0.876777 &  0.929648 &  0.902439 &   199.00000 \\
accuracy     &   0.802710 &  0.802710 &  0.802710 &     0.80271 \\
macro avg    &   0.803474 &  0.802071 &  0.801565 &  3173.00000 \\
weighted avg &   0.803860 &  0.802710 &  0.802062 &  3173.00000 \\
\bottomrule
\end{tabular}
